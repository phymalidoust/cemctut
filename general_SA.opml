<?xml version="1.0" encoding="UTF-8"?>
<opml version="2.0">
  <head>
    <title></title>
    <dateModified></dateModified>
    <ownerName></ownerName>
  </head>
  <body>
<outline text="Generic terms and algorithm of simulated annealing method" _note="Among the optimization algorithms, simulated annealing (SA) possesses&#10;outstanding aspects such as finding global extermum of highly&#10;complicated functions without getting caught at local extremums. For&#10;small and less complicated systems other algorithms such as *hill&#10;climbing* or *random walk* might be sufficient. However, they always&#10;have their own risks: The former can stuck in a local minimum and the&#10;latter may never converge. Nonetheless, when a large and highly&#10;complicated and large problems are in question, SA algorithms shows&#10;great successes and provide good estimations (not the very best, of&#10;course). The history of SA potimization technique goes back to 1980s&#10;\[1-3\].&#10;&#10;The algorithm of SA to find, for example, the global mimimum of a&#10;function *E*(*x*) is as follows (*E*(*x*) can be the energy of a system&#10;as a function a variable *x*).&#10;&#10;It considers an interval for the variable&#10;*x* ∈ \[*x*_(*m**i**n*) : *x*_(*m**a**x*)\]. Next, starts with two&#10;intial guesses for the variable *x* = *x*_(*r*)^(1, 2) that are chosen&#10;at random within the given interval for a fake 'temperature'&#10;*T* ∈ \[*T*_(*m**a**x*) : *T*_(*m**i**n*)\] and calculates&#10;*E*(*x*_(*r*)^(1, 2)). Finds their difference&#10;*Δ**E* = *E*(*x*_(*r*)²) − *E*(*x*_(*r*)¹). Since it is going to find&#10;minimum, if *Δ**E* &amp;lt; 0, then keeps solution *x*_(*r*)¹. Otherwise, if&#10;exp (*Δ**E*/*T*) &amp;gt; *X*_(*r*) then keeps *x*_(*r*)². In the Next step,&#10;it generates a new value for *E*(*x*_(*r*)^(*N*)) and compares with the&#10;previous solution *E*(*x*_(*r*)^(*P*)), namely constructs&#10;*Δ**E* = *E*(*x*_(*r*)^(*N*)) − *E*(*x*_(*r*)^(*P*)). This loop should&#10;be repeated for several times per each temperature value *T* and&#10;continues until *T* = *T*_(*m**i**n*).&#10;&#10;$$\\color{blue} {\\text{FOR}}\\;\\Big\\{\\;T=T\_{max}:T\_{min}\\;\\Big\\}\\;\\; \\\\&#10;x\_r^P = x\_r^1 = \\text{random}()\\,\\rightarrow E^P = E(x\_r^P)\\\\&#10;x\_r^N = x\_r^2 = \\text{random}()\\, \\rightarrow E^N = E(x\_r^N)\\\\&#10;\\Delta E = E^N - E^P\\\\&#10;\\color{red}{\\text{IF}}\\;\\Big\\{\\;\\Delta E &amp;lt;0\\;\\Big\\} \\;\\;\\;(\\text{hill climbing})\\\\&#10;x\_r^P =x\_r^N\\\\&#10;\\color{red}{\\text{ELSEIF}}\\;\\Big\\{\\;\\exp({{\\Delta E}/T})\\;&amp;gt; \\text{random}()\\;\\Big\\} \\;\\;\\;(\\text{random walk})\\\\&#10;x\_r^P =x\_r^N\\\\&#10;\\color{red}{\\text{ENDIF}}\\\\&#10;\\color{blue}{\\text{ENDFOR}}$$&#10;&#10;Below are two movies that show how SA algorithm tries to find a good&#10;solution.&#10;&#10;-   SA tries to find the global maximum without stopping at a local&#10;    maximum. By decreasing *T*, SA approaches the global maximum.&#10;&#10;![](/Users/phymalidoust/CEMC_tutorial/figures/Hill_Climbing_with_Simulated_Annealing.gif)&#10;&#10;-   SA tries to solve the famous travelling salesman problem among 125&#10;    points, i.e., finding a path that has the minimum length and&#10;    connects all 125 points.&#10;&#10;![](/Users/phymalidoust/CEMC_tutorial/figures/Travelling_salesman_problem_solved_with_simulated_annealing.gif)&#10;&#10;------------------------------------------------------------------------&#10;&#10;\[1\] S. Kirkpatrick, C. D. Gelatt Jr., M. P. Vecchi, *Optimization by&#10;Simulated Annealing*, [Science 220, 671&#10;(1983)](http://science.sciencemag.org/content/220/4598/671/tab-article-info).&#10;&#10;\[2\] S. Kirkpatrick, *Optimization by simulated annealing: Quantitative&#10;studies*, [Journal of Statistical Physics 34, 975&#10;(1984)](https://link.springer.com/article/10.1007/BF01009452).&#10;&#10;\[3\] P. J. M. van Laarhoven and E. H. L. Aarts, *Simulated Annealing:&#10;Theory and Applications*, [Springer,&#10;1988](https://www.springer.com/gp/book/9789027725134).">
</outline>
  </body>
</opml>
